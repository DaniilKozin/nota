#!/usr/bin/env swift

import Foundation
import AVFoundation
import Speech

print("ğŸ§ª Testing Nota Transcription System")
print("===================================")

// Test 1: Check microphone permissions
print("\n1ï¸âƒ£ Testing microphone permissions...")
let micStatus = AVCaptureDevice.authorizationStatus(for: .audio)
switch micStatus {
case .authorized:
    print("âœ… Microphone access: Authorized")
case .notDetermined:
    print("âš ï¸ Microphone access: Not determined - need to request")
case .denied:
    print("âŒ Microphone access: Denied")
case .restricted:
    print("âŒ Microphone access: Restricted")
@unknown default:
    print("â“ Microphone access: Unknown status")
}

// Test 2: Check Speech Recognition permissions
print("\n2ï¸âƒ£ Testing Speech Recognition permissions...")
let speechStatus = SFSpeechRecognizer.authorizationStatus()
switch speechStatus {
case .authorized:
    print("âœ… Speech Recognition: Authorized")
case .notDetermined:
    print("âš ï¸ Speech Recognition: Not determined - need to request")
case .denied:
    print("âŒ Speech Recognition: Denied")
case .restricted:
    print("âŒ Speech Recognition: Restricted")
@unknown default:
    print("â“ Speech Recognition: Unknown status")
}

// Test 3: Check available languages
print("\n3ï¸âƒ£ Testing available languages...")
let availableLocales = SFSpeechRecognizer.supportedLocales()
print("âœ… Supported locales count: \(availableLocales.count)")
for locale in availableLocales.prefix(10) {
    let recognizer = SFSpeechRecognizer(locale: locale)
    let available = recognizer?.isAvailable ?? false
    print("   \(locale.identifier): \(available ? "âœ…" : "âŒ")")
}

// Test 4: Check audio devices
print("\n4ï¸âƒ£ Testing audio devices...")
let audioDevices = AVCaptureDevice.DiscoverySession(
    deviceTypes: [.builtInMicrophone, .externalUnknown],
    mediaType: .audio,
    position: .unspecified
).devices

print("âœ… Found \(audioDevices.count) audio devices:")
for device in audioDevices {
    print("   ğŸ“± \(device.localizedName) (ID: \(device.uniqueID))")
}

// Test 5: Check UserDefaults settings
print("\n5ï¸âƒ£ Testing UserDefaults settings...")
let openaiKey = UserDefaults.standard.string(forKey: "openaiKey") ?? ""
let deepgramKey = UserDefaults.standard.string(forKey: "deepgramKey") ?? ""
let transcriptionProvider = UserDefaults.standard.string(forKey: "transcriptionProvider") ?? "auto"

print("OpenAI Key: \(openaiKey.isEmpty ? "âŒ Not set" : "âœ… Set (sk-...)")")
print("Deepgram Key: \(deepgramKey.isEmpty ? "âŒ Not set" : "âœ… Set")")
print("Transcription Provider: \(transcriptionProvider)")

// Test 6: Test audio engine setup
print("\n6ï¸âƒ£ Testing audio engine setup...")
let audioEngine = AVAudioEngine()
let inputNode = audioEngine.inputNode
let recordingFormat = inputNode.outputFormat(forBus: 0)

print("Audio Engine:")
print("   Sample Rate: \(recordingFormat.sampleRate)Hz")
print("   Channels: \(recordingFormat.channelCount)")
print("   Format: \(recordingFormat.commonFormat.rawValue)")

// Test 7: Test OpenAI API connectivity (if key is available)
if !openaiKey.isEmpty && openaiKey.hasPrefix("sk-") {
    print("\n7ï¸âƒ£ Testing OpenAI API connectivity...")
    
    var request = URLRequest(url: URL(string: "https://api.openai.com/v1/models")!)
    request.setValue("Bearer \(openaiKey)", forHTTPHeaderField: "Authorization")
    
    let semaphore = DispatchSemaphore(value: 0)
    
    URLSession.shared.dataTask(with: request) { data, response, error in
        defer { semaphore.signal() }
        
        if let error = error {
            print("âŒ OpenAI API Error: \(error.localizedDescription)")
            return
        }
        
        if let httpResponse = response as? HTTPURLResponse {
            print("âœ… OpenAI API Status: \(httpResponse.statusCode)")
            
            if httpResponse.statusCode == 200 {
                print("âœ… OpenAI API: Connected successfully")
            } else {
                print("âŒ OpenAI API: HTTP \(httpResponse.statusCode)")
            }
        }
    }.resume()
    
    semaphore.wait()
} else {
    print("\n7ï¸âƒ£ Skipping OpenAI API test (no valid key)")
}

print("\nğŸ¯ Test Summary:")
print("================")
print("Microphone: \(micStatus == .authorized ? "âœ…" : "âŒ")")
print("Speech Recognition: \(speechStatus == .authorized ? "âœ…" : "âŒ")")
print("Audio Devices: \(audioDevices.count > 0 ? "âœ…" : "âŒ")")
print("OpenAI Key: \(!openaiKey.isEmpty ? "âœ…" : "âŒ")")

if micStatus != .authorized || speechStatus != .authorized {
    print("\nâš ï¸ PERMISSIONS NEEDED:")
    print("Run the app and grant microphone and speech recognition permissions")
}

if openaiKey.isEmpty {
    print("\nğŸ’¡ RECOMMENDATION:")
    print("Add OpenAI API key in settings for better transcription quality")
}

print("\nğŸš€ Ready to test recording!")